{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 - Quiz: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**1.**\n",
    "Suppose your training examples are sentences (sequences of words). Which of the following refers to the $j^{th}$ word in the $i^{th}$ training example?\n",
    "\n",
    "**$x^{(i)<j>}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**2.**\n",
    "Consider this RNN:\n",
    "\n",
    "![picture alt](https://i.ibb.co/ZdfCzsj/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "This specific type of architecture is appropriate when:\n",
    "\n",
    "**$T_x=T_y$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**3.**\n",
    "To which of these tasks would you apply a many-to-one RNN architecture? (Check all that apply).\n",
    "\n",
    "![picture alt](https://i.ibb.co/B2bXh9M/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "**Sentiment classification (input a piece of text and output a 0/1 to denote positive or negative sentiment)**\n",
    "\n",
    "**Gender recognition from speech (input an audio clip and output a label indicating the speaker’s gender)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**4.**\n",
    "You are training this RNN language model.\n",
    "\n",
    "![picture alt](https://i.ibb.co/nsV9xVj/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "At the $t^{th}$ time step, what is the RNN doing? Choose the best answer.\n",
    "\n",
    "**Estimating $P(y^{<t>} \\mid y^{<1>}, y^{<2>}, \\dots, y^{<t-1>}))$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**5.**\n",
    "You have finished training a language model RNN and are using it to sample random sentences, as follows:\n",
    "\n",
    "![picture alt](https://i.ibb.co/Kq7LXMS/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "What are you doing at each time step tt?\n",
    "\n",
    "**(i) Use the probabilities output by the RNN to randomly sample a chosen word for that time-step as $\\hat{y}^{<t>}$. (ii) Then pass this selected word to the next time-step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**6.**\n",
    "You are training an RNN, and find that your weights and activations are all taking on the value of NaN (“Not a Number”). Which of these is the most likely cause of this problem?\n",
    "\n",
    "**Exploding gradient problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**7.**\n",
    "Suppose you are training a LSTM. You have a 10000 word vocabulary, and are using an LSTM with 100-dimensional activations $a^{<t>}$. What is the dimension of $\\Gamma_u$ at each time step?\n",
    "\n",
    "**100**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**8.**\n",
    "Here’re the update equations for the GRU.\n",
    "\n",
    "![picture alt](https://i.ibb.co/pnLhjyM/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "Alice proposes to simplify the GRU by always removing the $\\Gamma_u$. I.e., setting $\\Gamma_u$ = 1. Betty proposes to simplify the GRU by removing the $\\Gamma_r$. I. e., setting $\\Gamma_r$ = 1 always. Which of these models is more likely to work without vanishing gradient problems even when trained on very long input sequences?\n",
    "\n",
    "**Betty’s model (removing $\\Gamma_r$), because if $\\Gamma_u \\approx 0$ for a timestep, the gradient can propagate back through that timestep without much decay.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**9.**\n",
    "Here are the equations for the GRU and the LSTM:\n",
    "\n",
    "![picture alt](https://i.ibb.co/349YHxm/WVhjo-PCu-Eee5-Rg5-IFJ7l8g-a7b6030c6e5a53b431fee7aaabecd9bd-Screen-Shot-2018-01-03-at-5-48-26-PM.png)\n",
    "\n",
    "From these, we can see that the Update Gate and Forget Gate in the LSTM play a role similar to _______ and ______ in the GRU. What should go in the the blanks?\n",
    "\n",
    "**$\\Gamma_u$  and  $1-\\Gamma_u$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**10.**\n",
    "You have a pet dog whose mood is heavily dependent on the current and past few days’ weather. You’ve collected data for the past 365 days on the weather, which you represent as a sequence as $x^{<1>}, \\dots, x^{<365>}$. You’ve also collected data on your dog’s mood, which you represent as $y^{<1>}, \\dots, y^{<365>}$. You’d like to build a model to map from $x \\rightarrow y$. Should you use a Unidirectional RNN or Bidirectional RNN for this problem?\n",
    "\n",
    "**Unidirectional RNN, because the value of $y^{<t>}$ depends only on $x^{<1>}, \\dots, x^{<t>}$, but not on  $x^{<t+1>}, \\dots, x^{<365>}$**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
