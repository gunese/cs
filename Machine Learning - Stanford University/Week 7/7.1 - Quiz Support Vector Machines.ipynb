{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7 - Quiz: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**1.**\n",
    "Suppose you have trained an SVM classifier with a Gaussian kernel, and it learned the following decision boundary on the training set:\n",
    "\n",
    "![picture alt](http://spark-public.s3.amazonaws.com/ml/images/12.1-b.jpg)\n",
    "\n",
    "When you measure the SVM's performance on a cross validation set, it does poorly. Should you try increasing or decreasing C? Increasing or decreasing σ^2?\n",
    "\n",
    "**It would be reasonable to try decreasing C. It would also be reasonable to try increasing σ^2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**2.**\n",
    "The formula for the Gaussian kernel is given by similarity(x,l^1) = exp(-||x-l^1||^2 / 2σ^2). The figure below shows a plot of f1 = similarity(x,l^1) when σ2=1.\n",
    "\n",
    "![picture alt](http://spark-public.s3.amazonaws.com/ml/images/12.2-question.jpg)\n",
    "\n",
    "\n",
    "Which of the following is a plot of f1 when σ^2=0.25?\n",
    "\n",
    "\n",
    "**![picture alt](http://spark-public.s3.amazonaws.com/ml/images/12.2-b.jpg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**3.**\n",
    "The SVM solves minθ C∑i=1^m y^(i)cost1(θ^Tx^(i)) + (1-y^(i))cost0(θ^Tx^(i)) + ∑j=1^n θ^2jmin where the functions cost0(z) cost1(z) look like this:\n",
    "\n",
    "![picture alt](http://spark-public.s3.amazonaws.com/ml/images/12.3.jpg)\n",
    "\n",
    "The first term in the objective is: C∑i=1^m y^(i)cost1(θ^Tx^(i)) + (1-y^(i))cost0(θ^Tx^(i)). This first term will be zero if two of the following four conditions hold true. Which are the two conditions that would guarantee that this term equals zero?\n",
    "\n",
    "**For every example with y^(i)=1, we have that θ^Tx^(i)≥1.**\n",
    "\n",
    "**For every example with y^(i)=0, we have that θ^Tx^(i)≤-1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**4.**\n",
    "Suppose you have a dataset with n = 10 features and m = 5000 examples. After training your logistic regression classifier with gradient descent, you find that it has underfit the training set and does not achieve the desired performance on the training or cross validation sets. Which of the following might be promising steps to take? Check all that apply.\n",
    "\n",
    "**Use an SVM with a Gaussian Kernel.**\n",
    "\n",
    "**Create / add new polynomial features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**5.**\n",
    "Which of the following statements are true? Check all that apply.\n",
    "\n",
    "**It is important to perform feature normalization before using the Gaussian kernel.**\n",
    "\n",
    "**The maximum value of the Gaussian kernel sim(x,l(1))) is 1.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
